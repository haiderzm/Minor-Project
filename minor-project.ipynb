{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:26:34.123846Z",
     "iopub.status.busy": "2023-11-20T20:26:34.123355Z",
     "iopub.status.idle": "2023-11-20T20:26:37.266179Z",
     "shell.execute_reply": "2023-11-20T20:26:37.265254Z",
     "shell.execute_reply.started": "2023-11-20T20:26:34.123799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils import spectral_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:32:19.407913Z",
     "iopub.status.busy": "2023-11-20T20:32:19.407203Z",
     "iopub.status.idle": "2023-11-20T20:32:23.020519Z",
     "shell.execute_reply": "2023-11-20T20:32:23.019711Z",
     "shell.execute_reply.started": "2023-11-20T20:32:19.407882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from math import exp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kornia.filters.sobel import Sobel\n",
    "import wandb\n",
    "from torchvision.utils import make_grid\n",
    "import gc\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure as SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:32:29.588187Z",
     "iopub.status.busy": "2023-11-20T20:32:29.587559Z",
     "iopub.status.idle": "2023-11-20T20:32:29.594601Z",
     "shell.execute_reply": "2023-11-20T20:32:29.593618Z",
     "shell.execute_reply.started": "2023-11-20T20:32:29.588153Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Metric and Other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:32:58.776869Z",
     "iopub.status.busy": "2023-11-20T20:32:58.776482Z",
     "iopub.status.idle": "2023-11-20T20:32:58.781717Z",
     "shell.execute_reply": "2023-11-20T20:32:58.780837Z",
     "shell.execute_reply.started": "2023-11-20T20:32:58.776836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize(sample):\n",
    "#     MIN_H = 0.0\n",
    "#     MAX_H = 8802.0\n",
    "    MIN_H = sample.min()\n",
    "    MAX_H = sample.max()\n",
    "    return (sample - MIN_H)/(MAX_H-MIN_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:33:10.352952Z",
     "iopub.status.busy": "2023-11-20T20:33:10.352290Z",
     "iopub.status.idle": "2023-11-20T20:33:10.361830Z",
     "shell.execute_reply": "2023-11-20T20:33:10.360842Z",
     "shell.execute_reply.started": "2023-11-20T20:33:10.352917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Sobel_older(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.filter = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "\n",
    "        Gx = torch.tensor([[2.0, 0.0, -2.0], [4.0, 0.0, -4.0], [2.0, 0.0, -2.0]])\n",
    "        Gy = torch.tensor([[2.0, 4.0, 2.0], [0.0, 0.0, 0.0], [-2.0, -4.0, -2.0]])\n",
    "        G = torch.cat([Gx.unsqueeze(0), Gy.unsqueeze(0)], 0)\n",
    "        G = G.unsqueeze(1)\n",
    "        self.filter.weight = nn.Parameter(G, requires_grad=False)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.filter(img)\n",
    "        x = torch.mul(x, x)\n",
    "        x = torch.sum(x, dim=1, keepdim=True)\n",
    "        x = torch.sqrt(x)\n",
    "#         x = (torch.tanh(x) + 1)/2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:33:22.487586Z",
     "iopub.status.busy": "2023-11-20T20:33:22.486875Z",
     "iopub.status.idle": "2023-11-20T20:33:22.494327Z",
     "shell.execute_reply": "2023-11-20T20:33:22.493185Z",
     "shell.execute_reply.started": "2023-11-20T20:33:22.487545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2, border=0 ,data_min=0.0 ,data_max=1.0 ):\n",
    "    \n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "    h, w = img1.shape[2:]\n",
    "\n",
    "    img1 = img1[border:h-border, border:w-border]\n",
    "    img2 = img2[border:h-border, border:w-border]\n",
    "\n",
    "    mse = np.mean((img1 - img2)**2)\n",
    "#     print(mse)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * math.log10((data_max - data_min)/ math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:33:56.887444Z",
     "iopub.status.busy": "2023-11-20T20:33:56.886750Z",
     "iopub.status.idle": "2023-11-20T20:33:56.893135Z",
     "shell.execute_reply": "2023-11-20T20:33:56.892122Z",
     "shell.execute_reply.started": "2023-11-20T20:33:56.887409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class gradientAwareLoss(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sobelFilter = Sobel().to('cuda')\n",
    "        self.l1Loss = nn.L1Loss().to('cuda')\n",
    "\n",
    "    def forward(self, hr, sr):\n",
    "        hrEdgeMap = self.sobelFilter(hr)\n",
    "        srEdgeMap = self.sobelFilter(sr)\n",
    "        return self.l1Loss(hrEdgeMap, srEdgeMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:34:08.487435Z",
     "iopub.status.busy": "2023-11-20T20:34:08.487060Z",
     "iopub.status.idle": "2023-11-20T20:34:08.575184Z",
     "shell.execute_reply": "2023-11-20T20:34:08.574174Z",
     "shell.execute_reply.started": "2023-11-20T20:34:08.487406Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 254, 254])\n"
     ]
    }
   ],
   "source": [
    "sobel_old = Sobel_older()\n",
    "inp = torch.rand([1,1,256,256])\n",
    "out = sobel_old(inp)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:38:49.354861Z",
     "iopub.status.busy": "2023-11-20T20:38:49.354469Z",
     "iopub.status.idle": "2023-11-20T20:38:49.362073Z",
     "shell.execute_reply": "2023-11-20T20:38:49.361057Z",
     "shell.execute_reply.started": "2023-11-20T20:38:49.354828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, hr_paths,lr_paths,transform = None):\n",
    "        self.load_dir_hr = hr_paths\n",
    "        self.load_dir_lr = lr_paths\n",
    "        self.tranform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        hr = normalize(cv2.imread(self.load_dir_hr[index])).astype(np.float32)\n",
    "        lr = normalize(cv2.imread(self.load_dir_lr[index])).astype(np.float32)\n",
    "        \n",
    "        \n",
    "        if self.tranform:\n",
    "            hr, lr = self.tranform(hr), self.tranform(lr)\n",
    "        \n",
    "        return hr, lr\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.load_dir_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:43:36.129338Z",
     "iopub.status.busy": "2023-11-20T20:43:36.128617Z",
     "iopub.status.idle": "2023-11-20T20:43:36.325457Z",
     "shell.execute_reply": "2023-11-20T20:43:36.324493Z",
     "shell.execute_reply.started": "2023-11-20T20:43:36.129303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train and Test Data Loader\n",
    "import cv2\n",
    "train_hr = glob.glob('/kaggle/input/imagesuperresolution-dataset-2x4x-scale2/dataset/train/hr/**.png')\n",
    "test_hr = glob.glob('/kaggle/input/imagesuperresolution-dataset-2x4x-scale2/dataset/test/hr/**.png')\n",
    "\n",
    "train_lr = glob.glob('/kaggle/input/imagesuperresolution-dataset-2x4x-scale2/dataset/train/lr_2/**.png')\n",
    "test_lr = glob.glob('/kaggle/input/imagesuperresolution-dataset-2x4x-scale2/dataset/test/lr_2/**.png')\n",
    "\n",
    "train_loader = DataLoader(Dataset(train_hr, train_lr,\n",
    "                                  transform = transforms.Compose([transforms.ToTensor()]))\n",
    "                            ,batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(Dataset(test_hr,test_lr,\n",
    "                                transform = transforms.Compose([transforms.ToTensor()]))\n",
    "                                ,batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:43:50.908663Z",
     "iopub.status.busy": "2023-11-20T20:43:50.908183Z",
     "iopub.status.idle": "2023-11-20T20:44:08.743652Z",
     "shell.execute_reply": "2023-11-20T20:44:08.742694Z",
     "shell.execute_reply.started": "2023-11-20T20:43:50.908634Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([18, 3, 512, 512])\n",
      "torch.Size([18, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for hr , lr in test_loader:\n",
    "    print(hr.shape)\n",
    "    print(lr.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:07.429066Z",
     "iopub.status.busy": "2023-11-20T20:45:07.428307Z",
     "iopub.status.idle": "2023-11-20T20:45:12.226355Z",
     "shell.execute_reply": "2023-11-20T20:45:12.225179Z",
     "shell.execute_reply.started": "2023-11-20T20:45:07.429031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DepthwiseSeparableConvolution_Pytorch'...\n",
      "remote: Enumerating objects: 105, done.\u001b[K\n",
      "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
      "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
      "remote: Total 105 (delta 57), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (105/105), 312.97 KiB | 5.05 MiB/s, done.\n",
      "Resolving deltas: 100% (57/57), done.\n",
      "/kaggle/working/StyleSwin/DepthwiseSeparableConvolution_Pytorch\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/seungjunlee96/DepthwiseSeparableConvolution_Pytorch.git\n",
    "%cd DepthwiseSeparableConvolution_Pytorch/\n",
    "!python3 setup.py install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:14.908913Z",
     "iopub.status.busy": "2023-11-20T20:45:14.908487Z",
     "iopub.status.idle": "2023-11-20T20:45:14.916580Z",
     "shell.execute_reply": "2023-11-20T20:45:14.915591Z",
     "shell.execute_reply.started": "2023-11-20T20:45:14.908874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from DepthwiseSeparableConvolution import depthwise_separable_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:21.329907Z",
     "iopub.status.busy": "2023-11-20T20:45:21.329502Z",
     "iopub.status.idle": "2023-11-20T20:45:21.336018Z",
     "shell.execute_reply": "2023-11-20T20:45:21.335114Z",
     "shell.execute_reply.started": "2023-11-20T20:45:21.329874Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/StyleSwin\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:22.124813Z",
     "iopub.status.busy": "2023-11-20T20:45:22.124461Z",
     "iopub.status.idle": "2023-11-20T20:45:22.969388Z",
     "shell.execute_reply": "2023-11-20T20:45:22.968335Z",
     "shell.execute_reply.started": "2023-11-20T20:45:22.124764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 0.6585361957550049\n",
      "Out shape torch.Size([16, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def get_padding(kernel_size, dilation=1):\n",
    "    return int((kernel_size * dilation - dilation) / 2)\n",
    "\n",
    "\n",
    "LRELU_SLOPE = 0.1\n",
    "\n",
    "\n",
    "class AddSkipConn(nn.Module):\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.add = torch.nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.add.add(x, self.net(x))\n",
    "\n",
    "\n",
    "class ConcatSkipConn(nn.Module):\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([x, self.net(x)], 1)\n",
    "\n",
    "\n",
    "class FourierUnit(torch.nn.Module):\n",
    "    \"\"\"Implements Fourier Unit block.\n",
    "\n",
    "    Applies FFT to tensor and performs convolution in spectral domain.\n",
    "    After that return to time domain with Inverse FFT.\n",
    "\n",
    "    Attributes:\n",
    "        inter_conv: conv-bn-relu block that performs conv in spectral domain\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        fu_kernel: int = 1,\n",
    "        padding_type: str = \"reflect\",\n",
    "        fft_norm: str = \"ortho\",\n",
    "        use_only_freq: bool = False,\n",
    "        norm_layer=nn.BatchNorm2d,\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fft_norm = fft_norm\n",
    "        self.use_only_freq = use_only_freq\n",
    "\n",
    "        self.inter_conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels * 2,\n",
    "                out_channels * 2,\n",
    "                kernel_size=fu_kernel,\n",
    "                stride=1,\n",
    "                padding=get_padding(fu_kernel),\n",
    "                padding_mode=padding_type,\n",
    "                bias=bias,\n",
    "            ),\n",
    "            norm_layer(out_channels * 2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, ch, freq_dim, embed_dim = x.size()\n",
    "\n",
    "        dims_to_fft = (-2,) if self.use_only_freq else (-2, -1)\n",
    "        recover_length = (freq_dim,) if self.use_only_freq else (freq_dim, embed_dim)\n",
    "\n",
    "        fft_representation = torch.fft.rfftn(x, dim=dims_to_fft, norm=self.fft_norm)\n",
    "\n",
    "        # (B, Ch, 2, FFT_freq, FFT_embed)\n",
    "        fft_representation = torch.stack(\n",
    "            (fft_representation.real, fft_representation.imag), dim=2\n",
    "        )  # .view(batch_size, ch * 2, -1, embed_dim)\n",
    "\n",
    "        ffted_dims = fft_representation.size()[-2:]\n",
    "        fft_representation = fft_representation.view(\n",
    "            (\n",
    "                batch_size,\n",
    "                ch * 2,\n",
    "            )\n",
    "            + ffted_dims\n",
    "        )\n",
    "\n",
    "        fft_representation = (\n",
    "            self.inter_conv(fft_representation)\n",
    "            .view(\n",
    "                (\n",
    "                    batch_size,\n",
    "                    ch,\n",
    "                    2,\n",
    "                )\n",
    "                + ffted_dims\n",
    "            )\n",
    "            .permute(0, 1, 3, 4, 2)\n",
    "        )\n",
    "\n",
    "        fft_representation = torch.complex(\n",
    "            fft_representation[..., 0], fft_representation[..., 1]\n",
    "        )\n",
    "\n",
    "        reconstructed_x = torch.fft.irfftn(\n",
    "            fft_representation, dim=dims_to_fft, s=recover_length, norm=self.fft_norm\n",
    "        )\n",
    "\n",
    "        assert reconstructed_x.size() == x.size()\n",
    "\n",
    "        return reconstructed_x\n",
    "\n",
    "\n",
    "class SpectralTransform(torch.nn.Module):\n",
    "    \"\"\"Implements Spectrals Transform block.\n",
    "\n",
    "    Residual Block containing Fourier Unit with convolutions before and after.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        fu_kernel: int = 1,\n",
    "        padding_type: str = \"reflect\",\n",
    "        fft_norm: str = \"ortho\",\n",
    "        use_only_freq: bool = False,\n",
    "        norm_layer=nn.BatchNorm2d,\n",
    "        bias: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        halved_out_ch = out_channels // 2\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, halved_out_ch, kernel_size=1, stride=1, bias=bias),\n",
    "            norm_layer(halved_out_ch),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.fu = FourierUnit(\n",
    "            halved_out_ch,\n",
    "            halved_out_ch,\n",
    "            fu_kernel=fu_kernel,\n",
    "            use_only_freq=use_only_freq,\n",
    "            fft_norm=fft_norm,\n",
    "            padding_type=padding_type,\n",
    "            norm_layer=norm_layer,\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            halved_out_ch, out_channels, kernel_size=1, stride=1, bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = self.conv1(x)\n",
    "        x = self.fu(residual)\n",
    "        x += residual\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FastFourierConvolution(torch.nn.Module):\n",
    "    \"\"\"Implements FFC block.\n",
    "\n",
    "    Divides Tensor in two branches: local and global. Local branch performs\n",
    "    convolutions and global branch applies Spectral Transform layer.\n",
    "    After performing transforms in local and global branches outputs are passed through BatchNorm + ReLU\n",
    "    and eventually concatenated. Based on proportion of input and output global channels if the number is equal\n",
    "    to zero respective blocks are replaced by Identity Transform.\n",
    "    For clarity refer to original paper.\n",
    "\n",
    "    Attributes:\n",
    "        local_in_channels: # input channels for l2l and l2g convs\n",
    "        local_out_channels: # output channels for l2l and g2l convs\n",
    "        global_in_channels: # input channels for g2l and g2g convs\n",
    "        global_out_channels: # output_channels for l2g and g2g convs\n",
    "        l2l_layer: local to local Convolution\n",
    "        l2g_layer: local to global Convolution\n",
    "        g2l_layer: global to local Convolution\n",
    "        g2g_layer: global to global Spectral Transform\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        alpha_in: float = 0.5,\n",
    "        alpha_out: float = 0.5,\n",
    "        kernel_size: int = 3,\n",
    "        padding_type: str = \"reflect\",\n",
    "        fu_kernel: int = 1,\n",
    "        fft_norm: str = \"ortho\",\n",
    "        bias: bool = True,\n",
    "        norm_layer=nn.BatchNorm2d,\n",
    "        activation=nn.ReLU(True),\n",
    "        use_only_freq: bool = False,\n",
    "    ):\n",
    "        \"\"\"Inits FFC module.\n",
    "\n",
    "        Args:\n",
    "            in_channels: total channels of tensor before dividing into local and global\n",
    "            alpha_in:\n",
    "                proportion of global channels as input\n",
    "            alpha_out:\n",
    "                proportion of global channels as output\n",
    "            use_only_freq:\n",
    "                controls dimensionality of fft in Fourier Unit. If false uses 2D fft in Fourier Unit affecting both\n",
    "                frequency and time dimensions, otherwise applies 1D FFT only to frequency dimension\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.global_in_channels = int(in_channels * alpha_in)\n",
    "        self.local_in_channels = in_channels - self.global_in_channels\n",
    "        self.global_out_channels = int(out_channels * alpha_out)\n",
    "        self.local_out_channels = out_channels - self.global_out_channels\n",
    "\n",
    "        padding = get_padding(kernel_size)\n",
    "\n",
    "        tmp_module = self._get_module_on_true_predicate(\n",
    "            self.local_in_channels > 0 and self.local_out_channels > 0,\n",
    "            nn.Conv2d,\n",
    "            nn.Identity,\n",
    "        )\n",
    "        self.l2l_layer = tmp_module(\n",
    "            self.local_in_channels,\n",
    "            self.local_out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=padding,\n",
    "            padding_mode=padding_type,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        tmp_module = self._get_module_on_true_predicate(\n",
    "            self.local_in_channels > 0 and self.global_out_channels > 0,\n",
    "            nn.Conv2d,\n",
    "            nn.Identity,\n",
    "        )\n",
    "        self.l2g_layer = tmp_module(\n",
    "            self.local_in_channels,\n",
    "            self.global_out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=padding,\n",
    "            padding_mode=padding_type,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        tmp_module = self._get_module_on_true_predicate(\n",
    "            self.global_in_channels > 0 and self.local_out_channels > 0,\n",
    "            nn.Conv2d,\n",
    "            nn.Identity,\n",
    "        )\n",
    "        self.g2l_layer = tmp_module(\n",
    "            self.global_in_channels,\n",
    "            self.local_out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=padding,\n",
    "            padding_mode=padding_type,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        tmp_module = self._get_module_on_true_predicate(\n",
    "            self.global_in_channels > 0 and self.global_out_channels > 0,\n",
    "            SpectralTransform,\n",
    "            nn.Identity,\n",
    "        )\n",
    "        self.g2g_layer = tmp_module(\n",
    "            self.global_in_channels,\n",
    "            self.global_out_channels,\n",
    "            fu_kernel=fu_kernel,\n",
    "            fft_norm=fft_norm,\n",
    "            padding_type=padding_type,\n",
    "            bias=bias,\n",
    "            norm_layer=norm_layer,\n",
    "            use_only_freq=use_only_freq,\n",
    "        )\n",
    "\n",
    "        self.local_bn_relu = (\n",
    "            nn.Sequential(norm_layer(self.local_out_channels), activation)\n",
    "            if self.local_out_channels != 0\n",
    "            else nn.Identity()\n",
    "        )\n",
    "\n",
    "        self.global_bn_relu = (\n",
    "            nn.Sequential(norm_layer(self.global_out_channels), activation)\n",
    "            if self.global_out_channels != 0\n",
    "            else nn.Identity()\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_module_on_true_predicate(\n",
    "        condition: bool, true_module=nn.Identity, false_module=nn.Identity\n",
    "    ):\n",
    "        if condition:\n",
    "            return true_module\n",
    "        else:\n",
    "            return false_module\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #  chunk into local and global channels\n",
    "        x_l, x_g = (\n",
    "            x[:, : self.local_in_channels, ...],\n",
    "            x[:, self.local_in_channels :, ...],\n",
    "        )\n",
    "        x_l = 0 if x_l.size()[1] == 0 else x_l\n",
    "        x_g = 0 if x_g.size()[1] == 0 else x_g\n",
    "\n",
    "        out_local, out_global = torch.Tensor(0).to(x.device), torch.Tensor(0).to(\n",
    "            x.device\n",
    "        )\n",
    "\n",
    "        if self.local_out_channels != 0:\n",
    "            out_local = self.l2l_layer(x_l) + self.g2l_layer(x_g)\n",
    "            out_local = self.local_bn_relu(out_local)\n",
    "\n",
    "        if self.global_out_channels != 0:\n",
    "            out_global = self.l2g_layer(x_l) + self.g2g_layer(x_g)\n",
    "            out_global = self.global_bn_relu(out_global)\n",
    "\n",
    "        #  (B, out_ch, F, T)\n",
    "        output = torch.cat((out_local, out_global), dim=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class FFCResNetBlock(torch.nn.Module):\n",
    "    \"\"\"Implements Residual FFC block.\n",
    "\n",
    "    Contains two FFC blocks with residual connection.\n",
    "\n",
    "    Wraps around FFC arguments.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        alpha_in: float = 0.5,\n",
    "        alpha_out: float = 0.5,\n",
    "        kernel_size: int = 3,\n",
    "        padding_type: str = \"reflect\",\n",
    "        bias: bool = True,\n",
    "        fu_kernel: int = 1,\n",
    "        fft_norm: str = \"ortho\",\n",
    "        use_only_freq: bool = False,\n",
    "        norm_layer=nn.BatchNorm2d,\n",
    "        activation=nn.ReLU(True),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ffc1 = FastFourierConvolution(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            alpha_in=alpha_in,\n",
    "            alpha_out=alpha_out,\n",
    "            kernel_size=kernel_size,\n",
    "            padding_type=padding_type,\n",
    "            fu_kernel=fu_kernel,\n",
    "            fft_norm=fft_norm,\n",
    "            use_only_freq=use_only_freq,\n",
    "            bias=bias,\n",
    "            norm_layer=norm_layer,\n",
    "            activation=activation,\n",
    "        )\n",
    "\n",
    "        self.ffc2 = FastFourierConvolution(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            alpha_in=alpha_in,\n",
    "            alpha_out=alpha_out,\n",
    "            kernel_size=kernel_size,\n",
    "            padding_type=padding_type,\n",
    "            fu_kernel=fu_kernel,\n",
    "            fft_norm=fft_norm,\n",
    "            use_only_freq=use_only_freq,\n",
    "            bias=bias,\n",
    "            norm_layer=norm_layer,\n",
    "            activation=activation,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ffc1(x)\n",
    "        # out = self.ffc2(out)\n",
    "        return x \n",
    "    \n",
    "    \n",
    "inp = torch.rand([16,64,128,128])\n",
    "\n",
    "ffc = FastFourierConvolution(64,64,kernel_size=5,use_only_freq=False)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "out = ffc(inp)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "# print(ffc)\n",
    "\n",
    "print(\"Out shape\",out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:22.971803Z",
     "iopub.status.busy": "2023-11-20T20:45:22.971384Z",
     "iopub.status.idle": "2023-11-20T20:45:23.130884Z",
     "shell.execute_reply": "2023-11-20T20:45:23.129828Z",
     "shell.execute_reply.started": "2023-11-20T20:45:22.971738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4, 128, 128])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RefinementBlock(nn.Module):\n",
    "    def __init__(self,inp_channel,out_channel,kernel_sizes=[3,5,7]):\n",
    "        super().__init__()\n",
    "        self.inp = inp_channel\n",
    "        self.out = out_channel\n",
    "        self.kernel_size = kernel_sizes\n",
    "\n",
    "        self.ffc0 = FastFourierConvolution(inp_channel,out_channel,kernel_size=kernel_sizes[0])\n",
    "        self.ffc1 = FastFourierConvolution(inp_channel,out_channel,kernel_size=kernel_sizes[1])\n",
    "        self.ffc2 = FastFourierConvolution(inp_channel,out_channel,kernel_size=kernel_sizes[2])\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x0 = self.ffc0(x)\n",
    "        x1 = self.ffc1(x)\n",
    "        x2 = self.ffc2(x)\n",
    "        \n",
    "        return x + x0 + x1 + x2 \n",
    "    \n",
    "inp = torch.rand([12,4,128,128])\n",
    "rb = RefinementBlock(4,4)\n",
    "\n",
    "out = rb(inp)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:23.288131Z",
     "iopub.status.busy": "2023-11-20T20:45:23.287768Z",
     "iopub.status.idle": "2023-11-20T20:45:23.297745Z",
     "shell.execute_reply": "2023-11-20T20:45:23.296851Z",
     "shell.execute_reply.started": "2023-11-20T20:45:23.288102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ERAM(nn.Module):\n",
    "    def __init__(self, channel_begin, dimension):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(channel_begin, channel_begin, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avgpool = nn.AvgPool2d(dimension)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channel_begin, channel_begin//2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channel_begin//2, channel_begin, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(channel_begin, channel_begin, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.dconv = depthwise_separable_conv(channel_begin, channel_begin, kernel_size = 3, padding = 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        si_ca = self.avgpool(x) + torch.var_mean(x, dim=(2,3))[0].unsqueeze(2).unsqueeze(2)\n",
    "        mi_ca = self.conv2(self.relu(self.conv1(si_ca)))\n",
    "\n",
    "        mi_sa = self.conv3(self.relu(self.dconv(x)))\n",
    "\n",
    "        return self.sigmoid(mi_ca+mi_sa) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:23.748982Z",
     "iopub.status.busy": "2023-11-20T20:45:23.748635Z",
     "iopub.status.idle": "2023-11-20T20:45:23.756355Z",
     "shell.execute_reply": "2023-11-20T20:45:23.755351Z",
     "shell.execute_reply.started": "2023-11-20T20:45:23.748954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RepetitiveBlock(nn.Module):\n",
    "    def __init__(self,input_channel,out_channel,dimension=128,kernel_sizes=[3,5,7]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_channel = input_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.dimension = dimension\n",
    "        \n",
    "        self.refinement = RefinementBlock(inp_channel=self.input_channel,\n",
    "                                          out_channel=self.out_channel,\n",
    "                                          kernel_sizes=self.kernel_sizes)\n",
    "        \n",
    "        self.eram = ERAM(channel_begin=self.out_channel,dimension=self.dimension)\n",
    "        self.gelu = nn.GELU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.refinement(x)\n",
    "        x = self.eram(x)\n",
    "        x = self.gelu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:24.109169Z",
     "iopub.status.busy": "2023-11-20T20:45:24.108816Z",
     "iopub.status.idle": "2023-11-20T20:45:24.241818Z",
     "shell.execute_reply": "2023-11-20T20:45:24.240853Z",
     "shell.execute_reply.started": "2023-11-20T20:45:24.109140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4, 128, 128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand([12,4,128,128])\n",
    "rb = RepetitiveBlock(input_channel=4,out_channel=4)\n",
    "\n",
    "out = rb(inp)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:25.436043Z",
     "iopub.status.busy": "2023-11-20T20:45:25.435176Z",
     "iopub.status.idle": "2023-11-20T20:45:25.463523Z",
     "shell.execute_reply": "2023-11-20T20:45:25.462570Z",
     "shell.execute_reply.started": "2023-11-20T20:45:25.436006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import time\n",
    "from DepthwiseSeparableConvolution import depthwise_separable_conv\n",
    "\n",
    "\n",
    "\n",
    "class RefinementBlock(nn.Module):\n",
    "    def __init__(self,inp_channel,out_channel,kernel_sizes=[3,5,7]):\n",
    "        super().__init__()\n",
    "        self.inp = inp_channel # channel needs to be even\n",
    "        self.out = out_channel\n",
    "        self.kernel_size = kernel_sizes\n",
    "\n",
    "        self.ffc0 = FastFourierConvolution(inp_channel,out_channel,kernel_size=kernel_sizes[0])\n",
    "        self.ffc1 = FastFourierConvolution(inp_channel,out_channel,kernel_size=kernel_sizes[1])\n",
    "        self.ffc2 = FastFourierConvolution(inp_channel,out_channel,kernel_size=kernel_sizes[2])\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x0 = self.ffc0(x)\n",
    "        x1 = self.ffc1(x)\n",
    "        x2 = self.ffc2(x)\n",
    "        \n",
    "        return x + x0 + x1 + x2 \n",
    "    \n",
    "\n",
    "        \n",
    "class ERAM(nn.Module):\n",
    "    def __init__(self, channel_begin, dimension):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(channel_begin, channel_begin, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avgpool = nn.AvgPool2d(dimension)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channel_begin, channel_begin//2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channel_begin//2, channel_begin, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(channel_begin, channel_begin, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.dconv = depthwise_separable_conv(channel_begin, channel_begin, kernel_size = 3, padding = 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        si_ca = self.avgpool(x) + torch.var_mean(x, dim=(2,3))[0].unsqueeze(2).unsqueeze(2)\n",
    "        mi_ca = self.conv2(self.relu(self.conv1(si_ca)))\n",
    "\n",
    "        mi_sa = self.conv3(self.relu(self.dconv(x)))\n",
    "\n",
    "        return self.sigmoid(mi_ca+mi_sa) * x\n",
    "\n",
    "\n",
    "class RepetitiveBlock(nn.Module):\n",
    "    def __init__(self,input_channel,out_channel,dimension=128,kernel_sizes=[3,5,7]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_channel = input_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.dimension = dimension\n",
    "        \n",
    "        self.refinement = RefinementBlock(inp_channel=self.input_channel,\n",
    "                                          out_channel=self.out_channel,\n",
    "                                          kernel_sizes=self.kernel_sizes)\n",
    "        \n",
    "        self.eram = ERAM(channel_begin=self.out_channel,dimension=self.dimension)\n",
    "        self.gelu = nn.GELU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.refinement(x)\n",
    "        x = self.eram(x)\n",
    "        x = self.gelu(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, inp_channel, out_channel, repitive_units=5 ,channel_expansion=16, scale_factor=2):\n",
    "        super().__init__()\n",
    "        self.scale_factor =scale_factor\n",
    "        self.channel_expansion = channel_expansion\n",
    "        \n",
    "        # feature extraction block\n",
    "        self.conv1 = nn.Conv2d(inp_channel,self.channel_expansion,kernel_size=3,padding='same')\n",
    "        self.conv2 = nn.Conv2d(self.channel_expansion,self.channel_expansion*4,kernel_size=3, padding='same')\n",
    "        self.conv3 = nn.Conv2d(self.channel_expansion*4,self.channel_expansion*4,kernel_size=3, padding='same')\n",
    "        \n",
    "        self.repetitive_units = 5\n",
    "        \n",
    "\n",
    "        self.repetive_blocks_1 = RepetitiveBlock(input_channel=self.channel_expansion,out_channel=self.channel_expansion)\n",
    "        self.repetive_blocks_2 = RepetitiveBlock(input_channel=self.channel_expansion,out_channel=self.channel_expansion)\n",
    "        self.repetive_blocks_3 = RepetitiveBlock(input_channel=self.channel_expansion,out_channel=self.channel_expansion)\n",
    "        self.repetive_blocks_4 = RepetitiveBlock(input_channel=self.channel_expansion,out_channel=self.channel_expansion)\n",
    "        self.repetive_blocks_5 = RepetitiveBlock(input_channel=self.channel_expansion,out_channel=self.channel_expansion)\n",
    "            \n",
    "        self.upsample_PixelShuffle = nn.PixelShuffle(int(scale_factor))\n",
    "        self.downsample_PixelShuffle = nn.PixelShuffle(int(1.0/scale_factor))\n",
    "        self.bicubic_upsample = nn.Upsample(mode='bicubic',scale_factor=self.scale_factor)\n",
    "        self.refinement_Block = ...\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(19,3,kernel_size=3,padding='same') # need to fix channel\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self,x0):\n",
    "        \n",
    "        # x0 -> inp -> (b,3, h, w)\n",
    "        x = self.relu(self.conv1(x0)) # (b,3, h, w) -> (b,16, h, w)\n",
    "       \n",
    "        x = self.repetive_blocks_1(x)  # (b,16, h, w) -> (b,16, h, w)\n",
    "        x = self.repetive_blocks_2(x)  # (b,16, h, w) -> (b,16, h, w)\n",
    "        x = self.repetive_blocks_3(x)  # (b,16, h, w) -> (b,16, h, w)\n",
    "        x = self.repetive_blocks_4(x)  # (b,16, h, w) -> (b,16, h, w)\n",
    "        x = self.repetive_blocks_5(x)  # (b,16, h, w) -> (b,16, h, w)\n",
    "        \n",
    "        x = self.conv2(x)   # (b,16, h, w) -> (b,64, h, w)\n",
    "        x = self.conv3(x)   # (b,64, h, w) -> (b,64, h, w)\n",
    "\n",
    "        x = self.upsample_PixelShuffle(x) #   # (b,16, h, w) -> (b,4, h*2, w*2)\n",
    "\n",
    "        x_bc_upsample = self.bicubic_upsample(x0)   # (b,3, h, w) -> (b,3, h*2, w*2)\n",
    "        \n",
    "        \n",
    "        x = torch.concat([x,x_bc_upsample],dim=1)   # (b,4, h, w)  + (b,3, h, w)  -> (b,7, h, w)\n",
    "        \n",
    "        x = self.conv4(x)   # (b,7, h, w) -> (b,3, h, w)\n",
    "        \n",
    "        return (self.tanh(x) + 1.0)/2.0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:26.889141Z",
     "iopub.status.busy": "2023-11-20T20:45:26.888465Z",
     "iopub.status.idle": "2023-11-20T20:45:29.399124Z",
     "shell.execute_reply": "2023-11-20T20:45:29.397903Z",
     "shell.execute_reply.started": "2023-11-20T20:45:26.889088Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 3, 256, 256])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand([12,3,128,128])\n",
    "gen = Generator(3,3)\n",
    "\n",
    "out = gen(inp)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:33.468775Z",
     "iopub.status.busy": "2023-11-20T20:45:33.468171Z",
     "iopub.status.idle": "2023-11-20T20:45:36.308454Z",
     "shell.execute_reply": "2023-11-20T20:45:36.307241Z",
     "shell.execute_reply.started": "2023-11-20T20:45:33.468743Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'StyleSwin'...\n",
      "remote: Enumerating objects: 114, done.\u001b[K\n",
      "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 114 (delta 25), reused 24 (delta 24), pack-reused 86\u001b[K\n",
      "Receiving objects: 100% (114/114), 11.54 MiB | 13.67 MiB/s, done.\n",
      "Resolving deltas: 100% (49/49), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/microsoft/StyleSwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:36.310952Z",
     "iopub.status.busy": "2023-11-20T20:45:36.310554Z",
     "iopub.status.idle": "2023-11-20T20:45:36.317687Z",
     "shell.execute_reply": "2023-11-20T20:45:36.316798Z",
     "shell.execute_reply.started": "2023-11-20T20:45:36.310907Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/StyleSwin\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/StyleSwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:36.637865Z",
     "iopub.status.busy": "2023-11-20T20:45:36.637147Z",
     "iopub.status.idle": "2023-11-20T20:45:48.213114Z",
     "shell.execute_reply": "2023-11-20T20:45:48.212044Z",
     "shell.execute_reply.started": "2023-11-20T20:45:36.637833Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (1.11.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:48.215582Z",
     "iopub.status.busy": "2023-11-20T20:45:48.215260Z",
     "iopub.status.idle": "2023-11-20T20:45:48.220966Z",
     "shell.execute_reply": "2023-11-20T20:45:48.220050Z",
     "shell.execute_reply.started": "2023-11-20T20:45:48.215553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from op import FusedLeakyReLU, upfirdn2d\n",
    "from models.basic_layers import (Blur, Downsample, EqualConv2d, EqualLinear,\n",
    "                                 ScaledLeakyReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:48.222806Z",
     "iopub.status.busy": "2023-11-20T20:45:48.222459Z",
     "iopub.status.idle": "2023-11-20T20:45:48.234604Z",
     "shell.execute_reply": "2023-11-20T20:45:48.233759Z",
     "shell.execute_reply.started": "2023-11-20T20:45:48.222754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel,\n",
    "        out_channel,\n",
    "        kernel_size,\n",
    "        downsample=False,\n",
    "        blur_kernel=[1, 3, 3, 1],\n",
    "        bias=True,\n",
    "        activate=True,\n",
    "        sn=False\n",
    "    ):\n",
    "        layers = []\n",
    "\n",
    "        if downsample:\n",
    "            factor = 2\n",
    "            p = (len(blur_kernel) - factor) + (kernel_size - 1)\n",
    "            pad0 = (p + 1) // 2\n",
    "            pad1 = p // 2\n",
    "\n",
    "            layers.append(Blur(blur_kernel, pad=(pad0, pad1)))\n",
    "\n",
    "            stride = 2\n",
    "            self.padding = 0\n",
    "\n",
    "        else:\n",
    "            stride = 1\n",
    "            self.padding = kernel_size // 2\n",
    "\n",
    "        if sn:\n",
    "            # Not use equal conv2d when apply SN\n",
    "            layers.append(\n",
    "                spectral_norm(nn.Conv2d(\n",
    "                    in_channel,\n",
    "                    out_channel,\n",
    "                    kernel_size,\n",
    "                    padding=self.padding,\n",
    "                    stride=stride,\n",
    "                    bias=bias and not activate,\n",
    "                ))\n",
    "            )\n",
    "        else:\n",
    "            layers.append(\n",
    "                EqualConv2d(\n",
    "                    in_channel,\n",
    "                    out_channel,\n",
    "                    kernel_size,\n",
    "                    padding=self.padding,\n",
    "                    stride=stride,\n",
    "                    bias=bias and not activate,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if activate:\n",
    "            if bias:\n",
    "                layers.append(FusedLeakyReLU(out_channel))\n",
    "            else:\n",
    "                layers.append(ScaledLeakyReLU(0.2))\n",
    "\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:48.237308Z",
     "iopub.status.busy": "2023-11-20T20:45:48.236756Z",
     "iopub.status.idle": "2023-11-20T20:45:48.247232Z",
     "shell.execute_reply": "2023-11-20T20:45:48.246410Z",
     "shell.execute_reply.started": "2023-11-20T20:45:48.237279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, blur_kernel=[1, 3, 3, 1], sn=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = ConvLayer(in_channel, in_channel, 3, sn=sn)\n",
    "        self.conv2 = ConvLayer(in_channel, out_channel, 3, downsample=True, sn=sn)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv1(input)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:48.248596Z",
     "iopub.status.busy": "2023-11-20T20:45:48.248308Z",
     "iopub.status.idle": "2023-11-20T20:45:48.256891Z",
     "shell.execute_reply": "2023-11-20T20:45:48.255941Z",
     "shell.execute_reply.started": "2023-11-20T20:45:48.248569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_haar_wavelet(in_channels):\n",
    "    haar_wav_l = 1 / (2 ** 0.5) * torch.ones(1, 2)\n",
    "    haar_wav_h = 1 / (2 ** 0.5) * torch.ones(1, 2)\n",
    "    haar_wav_h[0, 0] = -1 * haar_wav_h[0, 0]\n",
    "\n",
    "    haar_wav_ll = haar_wav_l.T * haar_wav_l\n",
    "    haar_wav_lh = haar_wav_h.T * haar_wav_l\n",
    "    haar_wav_hl = haar_wav_l.T * haar_wav_h\n",
    "    haar_wav_hh = haar_wav_h.T * haar_wav_h\n",
    "\n",
    "    return haar_wav_ll, haar_wav_lh, haar_wav_hl, haar_wav_hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:48.260687Z",
     "iopub.status.busy": "2023-11-20T20:45:48.260400Z",
     "iopub.status.idle": "2023-11-20T20:45:48.269456Z",
     "shell.execute_reply": "2023-11-20T20:45:48.268682Z",
     "shell.execute_reply.started": "2023-11-20T20:45:48.260662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HaarTransform(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        ll, lh, hl, hh = get_haar_wavelet(in_channels)\n",
    "\n",
    "        self.register_buffer('ll', ll)\n",
    "        self.register_buffer('lh', lh)\n",
    "        self.register_buffer('hl', hl)\n",
    "        self.register_buffer('hh', hh)\n",
    "\n",
    "    def forward(self, input):\n",
    "        ll = upfirdn2d(input, self.ll, down=2)\n",
    "        lh = upfirdn2d(input, self.lh, down=2)\n",
    "        hl = upfirdn2d(input, self.hl, down=2)\n",
    "        hh = upfirdn2d(input, self.hh, down=2)\n",
    "\n",
    "        return torch.cat((ll, lh, hl, hh), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:48.271205Z",
     "iopub.status.busy": "2023-11-20T20:45:48.270682Z",
     "iopub.status.idle": "2023-11-20T20:45:48.279486Z",
     "shell.execute_reply": "2023-11-20T20:45:48.278653Z",
     "shell.execute_reply.started": "2023-11-20T20:45:48.271178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class InverseHaarTransform(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        ll, lh, hl, hh = get_haar_wavelet(in_channels)\n",
    "\n",
    "        self.register_buffer('ll', ll)\n",
    "        self.register_buffer('lh', -lh)\n",
    "        self.register_buffer('hl', -hl)\n",
    "        self.register_buffer('hh', hh)\n",
    "\n",
    "    def forward(self, input):\n",
    "        ll, lh, hl, hh = input.chunk(4, 1)\n",
    "        ll = upfirdn2d(ll, self.ll, up=2, pad=(1, 0, 1, 0))\n",
    "        lh = upfirdn2d(lh, self.lh, up=2, pad=(1, 0, 1, 0))\n",
    "        hl = upfirdn2d(hl, self.hl, up=2, pad=(1, 0, 1, 0))\n",
    "        hh = upfirdn2d(hh, self.hh, up=2, pad=(1, 0, 1, 0))\n",
    "\n",
    "        return ll + lh + hl + hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:48.281012Z",
     "iopub.status.busy": "2023-11-20T20:45:48.280677Z",
     "iopub.status.idle": "2023-11-20T20:45:48.288994Z",
     "shell.execute_reply": "2023-11-20T20:45:48.287966Z",
     "shell.execute_reply.started": "2023-11-20T20:45:48.280985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FromRGB(nn.Module):\n",
    "    def __init__(self, out_channel, downsample=True, blur_kernel=[1, 3, 3, 1], sn=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "        if downsample:\n",
    "            self.iwt = InverseHaarTransform(3)\n",
    "            self.downsample = Downsample(blur_kernel)\n",
    "            self.dwt = HaarTransform(3)\n",
    "\n",
    "        self.conv = ConvLayer(3 * 4, out_channel, 1, sn=sn)\n",
    "\n",
    "    def forward(self, input, skip=None):\n",
    "        if self.downsample:\n",
    "            input = self.iwt(input)\n",
    "            input = self.downsample(input)\n",
    "            input = self.dwt(input)\n",
    "\n",
    "        out = self.conv(input)\n",
    "\n",
    "        if skip is not None:\n",
    "            out = out + skip\n",
    "\n",
    "        return input, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:48.290441Z",
     "iopub.status.busy": "2023-11-20T20:45:48.290158Z",
     "iopub.status.idle": "2023-11-20T20:45:48.307208Z",
     "shell.execute_reply": "2023-11-20T20:45:48.306326Z",
     "shell.execute_reply.started": "2023-11-20T20:45:48.290416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, size, channel_multiplier=2, blur_kernel=[1, 3, 3, 1], sn=False, ssd=False):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = {\n",
    "            4: 512,\n",
    "            8: 512,\n",
    "            16: 512,\n",
    "            32: 512,\n",
    "            64: 256 * channel_multiplier,\n",
    "            128: 128 * channel_multiplier,\n",
    "            256: 64 * channel_multiplier,\n",
    "            512: 32 * channel_multiplier,\n",
    "            1024: 16 * channel_multiplier,\n",
    "        }\n",
    "\n",
    "        self.dwt = HaarTransform(3)\n",
    "\n",
    "        self.from_rgbs = nn.ModuleList()\n",
    "        self.convs = nn.ModuleList()\n",
    "\n",
    "        log_size = int(math.log(size, 2)) - 1\n",
    "\n",
    "        in_channel = channels[size]\n",
    "\n",
    "        for i in range(log_size, 2, -1):\n",
    "            out_channel = channels[2 ** (i - 1)]\n",
    "\n",
    "            self.from_rgbs.append(FromRGB(in_channel, downsample=i != log_size, sn=sn))\n",
    "            self.convs.append(ConvBlock(in_channel, out_channel, blur_kernel, sn=sn))\n",
    "\n",
    "            in_channel = out_channel\n",
    "\n",
    "        self.from_rgbs.append(FromRGB(channels[4], sn=sn))\n",
    "\n",
    "        self.stddev_group = 4\n",
    "        self.stddev_feat = 1\n",
    "\n",
    "        self.final_conv = ConvLayer(in_channel + 1, channels[4], 3, sn=sn)\n",
    "        if sn:\n",
    "            self.final_linear = nn.Sequential(\n",
    "                spectral_norm(nn.Linear(channels[4] * 4 * 4, channels[4])),\n",
    "                FusedLeakyReLU(channels[4]),\n",
    "                spectral_norm(nn.Linear(channels[4], 1)),\n",
    "        )\n",
    "        else:\n",
    "            self.final_linear = nn.Sequential(\n",
    "                EqualLinear(channels[4] * 4 * 4, channels[4], activation='fused_lrelu'),\n",
    "                EqualLinear(channels[4], 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.dwt(input)\n",
    "        out = None\n",
    "\n",
    "        for from_rgb, conv in zip(self.from_rgbs, self.convs):\n",
    "            input, out = from_rgb(input, out)\n",
    "            out = conv(out)\n",
    "\n",
    "        _, out = self.from_rgbs[-1](input, out)\n",
    "\n",
    "        batch, channel, height, width = out.shape\n",
    "        group = min(batch, self.stddev_group)\n",
    "        stddev = out.view(\n",
    "            group, -1, self.stddev_feat, channel // self.stddev_feat, height, width\n",
    "        )\n",
    "        stddev = torch.sqrt(stddev.var(0, unbiased=False) + 1e-8)\n",
    "        stddev = stddev.mean([2, 3, 4], keepdims=True).squeeze(2)\n",
    "        stddev = stddev.repeat(group, 1, height, width)\n",
    "        out = torch.cat([out, stddev], 1)\n",
    "\n",
    "        out = self.final_conv(out)\n",
    "\n",
    "        out = out.view(batch, -1)\n",
    "        out = self.final_linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:45:48.310662Z",
     "iopub.status.busy": "2023-11-20T20:45:48.310284Z",
     "iopub.status.idle": "2023-11-20T20:45:48.595861Z",
     "shell.execute_reply": "2023-11-20T20:45:48.594862Z",
     "shell.execute_reply.started": "2023-11-20T20:45:48.310628Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9260]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = Discriminator(size=256).to('cuda')\n",
    "inp = torch.randn(1, 3, 256, 256).to('cuda')\n",
    "out = disc(inp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:46:30.029018Z",
     "iopub.status.busy": "2023-11-20T20:46:30.028591Z",
     "iopub.status.idle": "2023-11-20T20:46:30.040608Z",
     "shell.execute_reply": "2023-11-20T20:46:30.039639Z",
     "shell.execute_reply.started": "2023-11-20T20:46:30.028986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "l1Loss = nn.L1Loss().to(device) \n",
    "edgeLoss = gradientAwareLoss().to(device) \n",
    "ssim = SSIM(data_range=1.0).to(device) \n",
    "anotherl1Loss = nn.L1Loss().to(device) \n",
    "\n",
    "optimizer = torch.optim.Adam(gen.parameters(), lr=1e-6 )\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:46:46.129195Z",
     "iopub.status.busy": "2023-11-20T20:46:46.128808Z",
     "iopub.status.idle": "2023-11-20T20:46:46.133882Z",
     "shell.execute_reply": "2023-11-20T20:46:46.132946Z",
     "shell.execute_reply.started": "2023-11-20T20:46:46.129163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "sobelFilter = Sobel().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:46:54.513864Z",
     "iopub.status.busy": "2023-11-20T20:46:54.513165Z",
     "iopub.status.idle": "2023-11-20T20:46:54.549517Z",
     "shell.execute_reply": "2023-11-20T20:46:54.548628Z",
     "shell.execute_reply.started": "2023-11-20T20:46:54.513831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0015, device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics import StructuralSimilarityIndexMeasure as SSIM\n",
    "ssim = SSIM(data_range=1.0).to('cuda')\n",
    "inp1 = torch.rand([1,1,256,256])\n",
    "inp2 = torch.rand([1,1,256,256])\n",
    "out = ssim(inp1,inp2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:47:34.878463Z",
     "iopub.status.busy": "2023-11-20T20:47:34.877529Z",
     "iopub.status.idle": "2023-11-20T20:47:34.893441Z",
     "shell.execute_reply": "2023-11-20T20:47:34.892470Z",
     "shell.execute_reply.started": "2023-11-20T20:47:34.878426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch):\n",
    "    print(f\"\\nEpoch {epoch}: \", end =\"\")\n",
    "    \n",
    "    l1_loss_per_epoch = 0.0\n",
    "    edge_loss_per_epoch = 0.0\n",
    "    ssim_loss_per_epoch = 0.0\n",
    "    ssim_per_epoch = 0.0\n",
    "    psnr_per_epoch = 0.0\n",
    "    total_loss_per_epoch = 0.0\n",
    "    \n",
    "    network.train()\n",
    "    loop = tqdm(train_loader)\n",
    "    for hr, lr in (loop):\n",
    "        \n",
    "        \n",
    "        # Forward Pass\n",
    "        batched_hr, batched_lr = hr.to(device), lr.to(device)\n",
    "        \n",
    "#         with torch.cuda.amp.autocast():\n",
    "        predicted_sr = network(batched_lr)\n",
    "\n",
    "        # Loss evaluation\n",
    "        l1_loss_per_sample = l1Loss(batched_hr*1000, predicted_sr*1000)\n",
    "        ssim_per_sample = ssim(batched_hr, predicted_sr)\n",
    "        ssim_loss_per_sample = 1 - ssim_per_sample\n",
    "\n",
    "        sobelhr = sobelFilter(batched_hr)*1000\n",
    "        sobelsr = sobelFilter(predicted_sr)*1000\n",
    "\n",
    "        edge_loss = l1Loss(sobelhr,sobelsr)\n",
    "            \n",
    "#             print(f'L1 Loss : {l1_loss_per_sample.item()}')\n",
    "#             print(f'Edge loss : {edge_loss.item()}')\n",
    "#             print(f'SSIM loss')\n",
    "\n",
    "        loop.set_postfix(L1_loss=f'{l1_loss_per_sample.item()}',\n",
    "                            Edge_loss = f'{edge_loss.item()}')\n",
    "        reconstruction_loss = l1_loss_per_sample + 100*(ssim_loss_per_sample) + 50*edge_loss\n",
    "        \n",
    "        t_loss = reconstruction_loss\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        psnr_per_sample = calculate_psnr(batched_hr.detach().cpu().numpy(), predicted_sr.detach().cpu().numpy())\n",
    "        \n",
    "        l1_loss_per_epoch += l1_loss_per_sample.item()\n",
    "        edge_loss_per_epoch += edge_loss.item() \n",
    "        ssim_loss_per_epoch += ssim_loss_per_sample.item() \n",
    "        ssim_per_epoch += ssim_per_sample.item()\n",
    "        psnr_per_epoch += psnr_per_sample \n",
    "        total_loss_per_epoch += t_loss.item()\n",
    "        \n",
    "    l1_loss_per_epoch /= float(len(train_loader))\n",
    "    edge_loss_per_epoch /= float(len(train_loader))\n",
    "    ssim_loss_per_epoch /= float(len(train_loader))\n",
    "    ssim_per_epoch /= float(len(train_loader))\n",
    "    psnr_per_epoch /= float(len(train_loader))\n",
    "    total_loss_per_epoch /= float(len(train_loader))\n",
    "#     scheduler.step()\n",
    "    wandb.log({\"Train L1 Loss\": l1_loss_per_epoch})\n",
    "    wandb.log({\"Train Edge Loss\": edge_loss_per_epoch})\n",
    "    wandb.log({\"Train SSIM Loss\": ssim_loss_per_epoch})\n",
    "    wandb.log({\"Train Total Loss\": total_loss_per_epoch})\n",
    "    wandb.log({\"Train SSIM\": ssim_per_epoch})\n",
    "    wandb.log({\"Train PSNR\": psnr_per_epoch})\n",
    "        \n",
    "    print(f\"(Train) L1 Loss: {l1_loss_per_epoch:.3f} | SSIM Loss: {ssim_loss_per_epoch:.3f} | Edge Loss: {edge_loss_per_epoch:.3f} | Total Loss: {total_loss_per_epoch:.3f}\")\n",
    "    print(f\"SSIM: {ssim_per_epoch:.3f} | PSNR: {psnr_per_epoch}\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    return psnr_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:47:51.543671Z",
     "iopub.status.busy": "2023-11-20T20:47:51.542762Z",
     "iopub.status.idle": "2023-11-20T20:47:51.557210Z",
     "shell.execute_reply": "2023-11-20T20:47:51.555915Z",
     "shell.execute_reply.started": "2023-11-20T20:47:51.543633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def valid_one_epoch(epoch):\n",
    "    ssim_per_epoch = 0.0\n",
    "    psnr_per_epoch = 0.0\n",
    "    b_ssim_per_epoch = 0.0\n",
    "    b_psnr_per_epoch = 0.0\n",
    "    \n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for hr, lr in tqdm(test_loader):\n",
    "            batched_hr, batched_lr = hr.to(device), lr.to(device)\n",
    "#             with torch.cuda.amp.autocast():\n",
    "            predicted_sr = network(batched_lr)\n",
    "                \n",
    "            bilinear_sr = F.interpolate(batched_lr, scale_factor=2, mode='bilinear')\n",
    "            \n",
    "#             print(\"Bil min : \",bilinear_sr.min())\n",
    "#             print(\"Bil max : \",bilinear_sr.max())\n",
    "\n",
    "            ssim_per_epoch += ssim(batched_hr, predicted_sr)\n",
    "            psnr_per_epoch += calculate_psnr(batched_hr.cpu().numpy(), predicted_sr.cpu().numpy())\n",
    "\n",
    "            b_ssim_per_epoch += ssim(batched_hr, bilinear_sr)\n",
    "            b_psnr_per_epoch += calculate_psnr(batched_hr.cpu().numpy(), bilinear_sr.cpu().numpy())\n",
    "\n",
    "            grid1 = make_grid(batched_lr[:4])\n",
    "            grid2 = make_grid(batched_hr[:4])\n",
    "            grid3 = make_grid(predicted_sr[:4])\n",
    "            grid4 = make_grid(bilinear_sr[:4])\n",
    "\n",
    "            grid1 = wandb.Image(grid1, caption=\"Low Resolution DEM\")\n",
    "            grid2 = wandb.Image(grid2, caption=\"High Resolution DEM\")\n",
    "            grid3 = wandb.Image(grid3, caption=\"Reconstructed High Resolution DEM\")\n",
    "            grid4 = wandb.Image(grid4, caption=\"Bilinear High Resolution DEM\")\n",
    "            \n",
    "            wandb.log({\"Original LR\": grid1})\n",
    "            wandb.log({\"Original HR\": grid2})\n",
    "            wandb.log({\"Reconstruced\": grid3})\n",
    "            wandb.log({\"Bilinear\": grid4})\n",
    "\n",
    "        ssim_per_epoch /= float(len(test_loader))\n",
    "        psnr_per_epoch /= float(len(test_loader))\n",
    "        b_ssim_per_epoch /= float(len(test_loader))\n",
    "        b_psnr_per_epoch /= float(len(test_loader))\n",
    "\n",
    "        wandb.log({\"Test Predicted SSIM\": ssim_per_epoch})\n",
    "        wandb.log({\"Test Predicted PSNR\": psnr_per_epoch})\n",
    "        wandb.log({\"Bilinear SSIM\": b_ssim_per_epoch})\n",
    "        wandb.log({\"Bilinear PSNR\": b_psnr_per_epoch})\n",
    "\n",
    "        print(f\"(Val) SSIM: {ssim_per_epoch:.3f} | PSNR: {psnr_per_epoch:.3f}\")\n",
    "        print(f\"(Bil) SSIM: {b_ssim_per_epoch:.3f} | PSNR: {b_psnr_per_epoch:.3f}\")\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return psnr_per_epoch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T20:48:07.529363Z",
     "iopub.status.busy": "2023-11-20T20:48:07.528435Z",
     "iopub.status.idle": "2023-11-20T20:48:07.836057Z",
     "shell.execute_reply": "2023-11-20T20:48:07.834801Z",
     "shell.execute_reply.started": "2023-11-20T20:48:07.529325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_psnr = 0\n",
    "count = 0\n",
    "prev_psnr =0 \n",
    "for i in range(150):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    train_psnr = train_one_epoch(i)\n",
    "    valid_psnr = valid_one_epoch(i)\n",
    "    \n",
    "    if valid_psnr >= prev_psnr:\n",
    "        count =0\n",
    "    else :\n",
    "        count +=1\n",
    "        \n",
    "        if count ==5 :\n",
    "            network = network.load_state_dict(torch.load(f\"best_model_{best_psnr}.pt\"))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if valid_psnr > best_psnr:\n",
    "        best_psnr = valid_psnr\n",
    "        torch.save(network.state_dict(), f\"best_model_{best_psnr}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4027045,
     "sourceId": 7004835,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
